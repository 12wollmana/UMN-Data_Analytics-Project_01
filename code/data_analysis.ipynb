{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis\n",
    "\n",
    "<em>Aaron Wollman, Albin Joseph, Kelsey Richardson Blackwell, Will Huang</em>\n",
    "\n",
    "In this notebook, the code will look at data from Spotify, Billboard, and the US Bureau of Labor Statistics to try to answer the following questions:\n",
    "<ul>\n",
    "    <li>Is there a correlation between unemployment and the Billboard Top 100 Songs Chart?  If so, can the data predict what the next top song might sound like?\n",
    "    </li>\n",
    "    <li>\n",
    "        Are there other musical attributes besides happiness that have a stronger correlation such as danceability, energy, tempo, speech?\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statistics\n",
    "import numpy as np\n",
    "from scipy.stats import linregress\n",
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/music_and_unemployment.csv')\n",
    "data.drop('Unnamed: 0',axis=1,inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aaron's Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from columns import Music_Unemploy_Cols, Unemploy_Cols\n",
    "from datafiles import music_unemployment, unemployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Music and Unemployment CSV\n",
    "music_unemployment = pd.read_csv(music_unemployment, index_col = 0)\n",
    "music_unemployment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployement_time = pd.read_csv(unemployment, index_col = 0)\n",
    "unemployement_time = unemployement_time.dropna()\n",
    "unemployement_time.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployement_time.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployement_time_pivot=unemployement_time.pivot(\n",
    "    Unemploy_Cols.year, Unemploy_Cols.month, Unemploy_Cols.rate)\n",
    "unemployement_time_pivot.dropna()\n",
    "unemployement_time_pivot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the Standard Deviation per Year\n",
    "temp=unemployement_time_pivot.copy()\n",
    "temp['STD']=[statistics.stdev(temp.loc[index,:]) for index,row in temp.iterrows()]\n",
    "temp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To show the how the unemployment rate has changed over time, the code will use a heatmap. The darker the shade of blue, the higher the unemployment rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show all years in one heatmap.\n",
    "plt.figure(figsize=(15,20))\n",
    "sns.heatmap(unemployement_time_pivot,cmap=(\"Blues\"))\n",
    "plt.title(\"Unemployment Rate between 1960 and 2020\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the heatmap per decade.  Should be equivalent to the above graph.\n",
    "vmax=unemployement_time_pivot.max().max()\n",
    "vmin=unemployement_time_pivot.min().min()\n",
    "fig,axes=plt.subplots(7,1,figsize=(10,20),sharex=True)\n",
    "i = 0\n",
    "for axis in axes:\n",
    "    data = unemployement_time_pivot[i*10 : (i+1) * 10]\n",
    "    axis.set_title(f\"Unemployment in the {1960 + (i*10)}s\")\n",
    "    sns.heatmap(data,cmap=(\"Blues\"),ax=axis,vmax=vmax,vmin=vmin)\n",
    "    i += 1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Song Valence\n",
    "[Spotify's API](https://developer.spotify.com/documentation/web-api/reference/tracks/get-audio-features/) defines a song's valence as:\n",
    "<blockquote>\"A measure from 0.0 to 1.0 describing the musical positiveness conveyed by a track. Tracks with high valence sound more positive (e.g. happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry).\"</blockquote>\n",
    "\n",
    "For this project, this can be considered our \\\"happiness\\\" metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Song Valence vs Unemployment\n",
    "To compare the song's valence to the unemployment, the code will first try to find a correlation between each month's average valence and the unemployment rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for plotting a regression\n",
    "def regression_plot(dataframe, x_col, y_col):\n",
    "    # Plot the scatter plot\n",
    "    dataframe.plot(kind=\"scatter\", x = x_col, y = y_col)\n",
    "    \n",
    "    # Calculate the correlation coefficient and linear regression model \n",
    "    x_values = dataframe[x_col]\n",
    "    y_values = dataframe[y_col]\n",
    "    (slope, intercept, rvalue, pvalue, stderr) = linregress(x_values, y_values)\n",
    "    regress_values = x_values * slope + intercept\n",
    "    equation = \"y = \" + str(round(slope,2)) + \"x + \" + str(round(intercept,2))\n",
    "    eq_label = f\"{equation} \\nr-squared = {round(rvalue * rvalue, 3)}\"\n",
    "    regress_plot, = plt.plot(x_values, regress_values, \"r-\", label=eq_label)\n",
    "    plt.legend(handles=[regress_plot], loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by the song's date\n",
    "date_cols = [Music_Unemploy_Cols.year, \n",
    "             Music_Unemploy_Cols.month, \n",
    "             Music_Unemploy_Cols.day]\n",
    "music_unemployment_gb = music_unemployment.groupby(date_cols)\n",
    "\n",
    "# Find the average of unemployment rate and weighed valence for each date\n",
    "avg_music_unemploy = music_unemployment_gb.mean()\n",
    "rate_v_valence = avg_music_unemploy[[Music_Unemploy_Cols.unemploy_rate, \n",
    "                                     Music_Unemploy_Cols.valence]]\n",
    "\n",
    "# Create a Scatter Graph\n",
    "regression_plot(rate_v_valence, \n",
    "                Music_Unemploy_Cols.unemploy_rate, \n",
    "                Music_Unemploy_Cols.valence)\n",
    "plt.title(\"Unemployment Rate vs. Valence (Happiness)\")\n",
    "plt.xlabel(\"Unemployment Rate\")\n",
    "plt.ylabel(\"Valence (Happiness)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above graph, there is <b>not</b> a good correlation between valence and the unemployment rate. With the above, the data doesn't take the song's placement in the Top 100 into account. Let's try again using a weighted average of the Top 100.\n",
    "\n",
    "This weighted average will give the number 1 song 101 points, number 2 100 points, and will keep decreasing by 1 point until it assigns the number 100 song 1 point. By doing this weighted average, the placement of a song on the Top 100 will be more meaningful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new data point \"Weighted Valence\"\n",
    "Music_Unemploy_Cols.weighed_valence = \"weighed valence\"\n",
    "weights = (101 - music_unemployment[Music_Unemploy_Cols.placement])\n",
    "weighed_valence = music_unemployment[Music_Unemploy_Cols.valence] * weights\n",
    "music_unemployment[Music_Unemploy_Cols.weighed_valence] = weighed_valence\n",
    "music_unemployment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by the song's date\n",
    "music_unemployment_gb = music_unemployment.groupby(date_cols)\n",
    "\n",
    "# Find the average of unemployment rate and weighed valence for each date\n",
    "avg_music_unemploy = music_unemployment_gb.mean()\n",
    "rate_v_valence = avg_music_unemploy[[Music_Unemploy_Cols.unemploy_rate, \n",
    "                                     Music_Unemploy_Cols.weighed_valence]]\n",
    "\n",
    "# Create a Scatter Graph\n",
    "regression_plot(rate_v_valence, \n",
    "                Music_Unemploy_Cols.unemploy_rate, \n",
    "                Music_Unemploy_Cols.weighed_valence)\n",
    "plt.title(\"Unemployment Rate vs. Valence (Happiness)\")\n",
    "plt.xlabel(\"Unemployment Rate\")\n",
    "plt.ylabel(\"Weighed Valence (Happiness)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even with a weighted average, there still isn't a good correlation between the average valence and the unemployment rate. Let's now look to see if there is another musical attribute that might correlate to unemployment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding an Alternative Music Attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment_rate_list=unemployement_time[Unemploy_Cols.rate]\n",
    "plt.boxplot(unemployment_rate_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# End of Aaron's Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kelsey's code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unemployment Rate vs. Happiness\n",
    "\n",
    "We ran a regression for happiness (\"valence\") versus Unemployment Rate and discovered that the unemployment rate does not impact happiness in a Top 100 hit song. If you look at the plot below, you can visibily see the scattered data points. The r value = 0.1, which means there is almost no relationship between happiness in a song and the unemployment rate.\n",
    "\n",
    "So we decided to dig a littler deeper and look at the other variables in music."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new data point \"Weighted Valence\"\n",
    "data[\"weighed valence\"] = data[\"valence\"] * (101 - data[\"Placement\"])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by the song's date\n",
    "data_gb = data.groupby([\"Year\", \"Month\", \"Day\"])\n",
    "\n",
    "# Find the average of unemployment rate and weighed valence for each date\n",
    "rate_v_valence = data_gb.mean()[[\"Unemployment Rate\", \"weighed valence\"]]\n",
    "\n",
    "# Create a Scatter Graph\n",
    "rate_v_valence.plot(kind=\"scatter\", x = \"Unemployment Rate\", y = \"weighed valence\")\n",
    "\n",
    "# Calculate the correlation coefficient and linear regression model \n",
    "x_values = rate_v_valence[\"Unemployment Rate\"]\n",
    "y_values = rate_v_valence[\"weighed valence\"]\n",
    "\n",
    "(slope, intercept, rvalue, pvalue, stderr) = linregress(x_values, y_values)\n",
    "regress_values = x_values * slope + intercept\n",
    "line_eq = \"y = \" + str(round(slope,2)) + \"x + \" + str(round(intercept,2))\n",
    "\n",
    "plt.plot(x_values,regress_values,\"r-\")\n",
    "plt.annotate(line_eq,(5,22),fontsize=15,color=\"red\")\n",
    "\n",
    "plt.title(\"Unemployment Rate vs. Valence (Happiness)\")\n",
    "plt.xlabel(\"Unemployment Rate\")\n",
    "plt.ylabel(\"Weighed Valence (Happiness)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unemployment Rate vs. Energy\n",
    "\n",
    "We ran a regression for the unemployment rate versus energy and discovered there is a positive relationship between the energy in a song and the unemployment rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"weighed energy\"] = data[\"energy\"] * (101 - data[\"Placement\"])\n",
    "data[\"weighed tempo\"] = data[\"tempo\"] * (101 - data[\"tempo\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by the song's date\n",
    "data_gb = data.groupby([\"Year\", \"Month\", \"Day\"])\n",
    "\n",
    "# Find the average of unemployment rate and weighed valence for each date\n",
    "rate_v_energy = data_gb.mean()[[\"Unemployment Rate\", \"weighed energy\"]]\n",
    "\n",
    "# Create a Scatter Graph\n",
    "rate_v_energy.plot(kind=\"scatter\", x = \"Unemployment Rate\", y = \"weighed energy\")\n",
    "\n",
    "# Calculate the correlation coefficient and linear regression model \n",
    "x_values = rate_v_energy[\"Unemployment Rate\"]\n",
    "y_values = rate_v_energy[\"weighed energy\"]\n",
    "\n",
    "(slope, intercept, rvalue, pvalue, stderr) = linregress(x_values, y_values)\n",
    "regress_values = x_values * slope + intercept\n",
    "line_eq = \"y = \" + str(round(slope,2)) + \"x + \" + str(round(intercept,2))\n",
    "\n",
    "plt.plot(x_values,regress_values,\"r-\")\n",
    "plt.annotate(line_eq,(5,22),fontsize=15,color=\"red\")\n",
    "\n",
    "plt.title(\"Unemployment Rate vs. Energy\")\n",
    "plt.xlabel(\"Unemployment Rate\")\n",
    "plt.ylabel(\"Energy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unemployment Rate vs. Tempo\n",
    "\n",
    "We ran a regression for the unemployment rate versus tempo and discovered there is a slight negative relationship between tempo in a song and the unemployment rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by the song's date\n",
    "data_gb = data.groupby([\"Year\", \"Month\", \"Day\"])\n",
    "\n",
    "# Find the average of unemployment rate and weighed valence for each date\n",
    "rate_v_tempo = data_gb.mean()[[\"Unemployment Rate\", \"weighed tempo\"]]\n",
    "\n",
    "# Create a Scatter Graph\n",
    "rate_v_tempo.plot(kind=\"scatter\", x = \"Unemployment Rate\", y = \"weighed tempo\")\n",
    "\n",
    "# Calculate the correlation coefficient and linear regression model \n",
    "x_values = rate_v_tempo[\"Unemployment Rate\"]\n",
    "y_values = rate_v_tempo[\"weighed tempo\"]\n",
    "\n",
    "(slope, intercept, rvalue, pvalue, stderr) = linregress(x_values, y_values)\n",
    "regress_values = x_values * slope + intercept\n",
    "line_eq = \"y = \" + str(round(slope,2)) + \"x + \" + str(round(intercept,2))\n",
    "\n",
    "plt.plot(x_values,regress_values,\"r-\")\n",
    "plt.annotate(line_eq,(8,-1800),fontsize=15,color=\"red\")\n",
    "\n",
    "plt.title(\"Unemployment Rate vs. Tempo\")\n",
    "plt.xlabel(\"Unemployment Rate\")\n",
    "plt.ylabel(\"Tempo\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# End of Kelsey's Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will's Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unemployment rate monthly data from 1960 to 2019 \n",
    "unemployment_time=data[['Year','Month','Unemployment Rate']].drop_duplicates().reset_index(drop=True)\n",
    "unemployment_time.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unemployment rate data by Year and Month\n",
    "unemployment_time_pivot=unemployment_time.pivot('Year','Month','Unemployment Rate')\n",
    "unemployment_time_pivot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the maximum of unemplyment rate\n",
    "vmax=unemployment_time_pivot.max().max()\n",
    "\n",
    "#the minimum of unemployment rate\n",
    "vmin=unemployment_time_pivot.min().min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unemployment rate heat map by decades\n",
    "fig,axes=plt.subplots(6,1,figsize=(15,20))\n",
    "sns.heatmap(unemployment_time_pivot[:10],cmap=(\"Blues\"),ax=axes[0],vmax=vmax,vmin=vmin)\n",
    "sns.heatmap(unemployment_time_pivot[10:20],cmap=(\"Blues\"),ax=axes[1],vmax=vmax,vmin=vmin)\n",
    "sns.heatmap(unemployment_time_pivot[20:30],cmap=(\"Blues\"),ax=axes[2],vmax=vmax,vmin=vmin)\n",
    "sns.heatmap(unemployment_time_pivot[30:40],cmap=(\"Blues\"),ax=axes[3],vmax=vmax,vmin=vmin)\n",
    "sns.heatmap(unemployment_time_pivot[40:50],cmap=(\"Blues\"),ax=axes[4],vmax=vmax,vmin=vmin)\n",
    "sns.heatmap(unemployment_time_pivot[50:],cmap=(\"Blues\"),ax=axes[5],vmax=vmax,vmin=vmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment_rate_list=[]\n",
    "for i in range(len(unemployment_time_pivot)):\n",
    "    for j in unemployment_time_pivot.iloc[i,1:]:\n",
    "        unemployment_rate_list.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if there is outlier in unemployemnt rate\n",
    "plt.boxplot(unemployment_rate_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#categorize song by its unemployment rate at the time\n",
    "# if unemployment rate higher than 7.0, assign into High_Unemployment group\n",
    "# 7.0 is descided by the 3rd quantile of all the unemployment rate data\n",
    "\n",
    "high_unemployment_rate=np.quantile(unemployment_rate_list, .75) ###7.0\n",
    "data[\"weighed valence\"] = data[\"valence\"] * (101 - data[\"Placement\"])\n",
    "data['High_Unemployment']=data['Unemployment Rate'].apply(lambda x: 1 if x>=high_unemployment_rate else 0)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the calculation of weighted features could be done together \n",
    "#this section should be move above of top of the jupyter nobebook\n",
    "\n",
    "music_unemployment[\"weighed valence\"] = music_unemployment[\"valence\"] * (101 - music_unemployment[\"Placement\"])\n",
    "music_unemployment['weighed danceability']=music_unemployment[\"danceability\"] * (101 - music_unemployment[\"Placement\"])\n",
    "music_unemployment['weighed energy']=music_unemployment[\"energy\"] * (101 - music_unemployment[\"Placement\"])\n",
    "music_unemployment['weighed key']=music_unemployment[\"key\"] * (101 - music_unemployment[\"Placement\"])\n",
    "music_unemployment['weighed loudness']=music_unemployment[\"loudness\"] * (101 - music_unemployment[\"Placement\"])\n",
    "music_unemployment['weighed speechiness']=music_unemployment[\"speechiness\"] * (101 - music_unemployment[\"Placement\"])\n",
    "music_unemployment['weighed acousticness']=music_unemployment[\"acousticness\"] * (101 - music_unemployment[\"Placement\"])\n",
    "music_unemployment['weighed liveness']=music_unemployment[\"liveness\"] * (101 - music_unemployment[\"Placement\"])\n",
    "music_unemployment['weighed tempo']=music_unemployment[\"tempo\"] * (101 - music_unemployment[\"Placement\"])\n",
    "music_unemployment['High_Unemployment']=music_unemployment['Unemployment Rate'].apply(lambda x: 1 if x>=high_unemployment_rate else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we could drop the original scroe and replace it by the weighted score\n",
    "music_unemployment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assign the weighted feature scores to the mean of the monthly feature score\n",
    "music_unemployment_group=music_unemployment.groupby(['Year','Month','Day'])[\n",
    "    ['High_Unemployment','Unemployment Rate',\n",
    "       'weighed valence', 'weighed danceability', 'weighed energy',\n",
    "       'weighed key', 'weighed loudness', 'weighed speechiness',\n",
    "       'weighed acousticness', 'weighed liveness', 'weighed tempo']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list=['weighed valence', 'weighed danceability', 'weighed energy',\n",
    "       'weighed key', 'weighed loudness', 'weighed speechiness',\n",
    "       'weighed acousticness', 'weighed liveness', 'weighed tempo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#scatter plots for weigthed feature scroes by unemployment rate\n",
    "row=0\n",
    "col=0\n",
    "fig,axes=plt.subplots(3,3,figsize=(15,15))\n",
    "\n",
    "for i in feature_list:\n",
    "    if col>2:\n",
    "        row+=1\n",
    "        col=0\n",
    "        sns.scatterplot(x='Unemployment Rate',y=i,hue='High_Unemployment',data=music_unemployment_group,ax=axes[row][col])\n",
    "        col+=1\n",
    "        \n",
    "    else:\n",
    "        sns.scatterplot(x='Unemployment Rate',y=i,hue='High_Unemployment',data=music_unemployment_group,ax=axes[row][col])\n",
    "        col+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#boxplots for weigthed feature scroes by unemployment rate\n",
    "row=0\n",
    "col=0\n",
    "fig,axes=plt.subplots(3,3,figsize=(15,15))\n",
    "for i in feature_list:\n",
    "    if col>2:\n",
    "        row+=1\n",
    "        col=0\n",
    "        sns.boxplot(x='High_Unemployment',y=i,data=music_unemployment_group[[i,'High_Unemployment']],ax=axes[row][col])\n",
    "        col+=1\n",
    "        \n",
    "    else:\n",
    "        sns.boxplot(x='High_Unemployment',y=i,data=music_unemployment_group[[i,'High_Unemployment']],ax=axes[row][col])\n",
    "        col+=1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#anova test for weighted features\n",
    "statistic_list=[]\n",
    "pvalue_list=[]\n",
    "for i in feature_list:\n",
    "    group1=music_unemployment_group[i][music_unemployment_group['High_Unemployment']==1]\n",
    "    group2=music_unemployment_group[i][music_unemployment_group['High_Unemployment']==0]\n",
    "    statistic=st.f_oneway(group1,group2)[0]\n",
    "    pvalue=st.f_oneway(group1,group2)[1]\n",
    "    statistic_list.append(statistic)\n",
    "    pvalue_list.append(pvalue)\n",
    "    print(f' ANOVA Result for {i} vs. High_Unemployment\\n {st.f_oneway(group1,group2)}\\n==================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#anova test results df\n",
    "significant_list=[1 if i <=0.05 else 0 for i in pvalue_list]\n",
    "anova=pd.DataFrame({'Feature':feature_list,'Statistic':statistic_list,'Pvalue':pvalue_list,'Significant':significant_list})\n",
    "anova.sort_values('Pvalue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#boxplots for the weighted fetures which has significant \n",
    "row=0\n",
    "col=0\n",
    "fig,axes=plt.subplots(2,3,figsize=(15,10))\n",
    "for i in anova['Feature'][anova['Significant']==1]:\n",
    "    if col>2:\n",
    "        row+=1\n",
    "        col=0\n",
    "        sns.boxplot(x='High_Unemployment',y=i,data=music_unemployment_group[[i,'High_Unemployment']],ax=axes[row][col])\n",
    "        col+=1\n",
    "        \n",
    "    else:\n",
    "        sns.boxplot(x='High_Unemployment',y=i,data=music_unemployment_group[[i,'High_Unemployment']],ax=axes[row][col])\n",
    "        col+=1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANOVA Test on Yearly Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "music_unemployment_group_y=music_unemployment.groupby(['Year'])[\n",
    "    ['Unemployment Rate',\n",
    "       'weighed valence', 'weighed danceability', 'weighed energy',\n",
    "       'weighed key', 'weighed loudness', 'weighed speechiness',\n",
    "       'weighed acousticness', 'weighed liveness', 'weighed tempo']].mean()\n",
    "music_unemployment_group_y['High_Unemployment']=music_unemployment_group_y['Unemployment Rate'].apply(lambda x: 1 if x>=high_unemployment_rate else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistic_list=[]\n",
    "pvalue_list=[]\n",
    "for i in feature_list:\n",
    "    group1=music_unemployment_group_y[i][music_unemployment_group_y['High_Unemployment']==1]\n",
    "    group2=music_unemployment_group_y[i][music_unemployment_group_y['High_Unemployment']==0]\n",
    "    statistic=st.f_oneway(group1,group2)[0]\n",
    "    pvalue=st.f_oneway(group1,group2)[1]\n",
    "    statistic_list.append(statistic)\n",
    "    pvalue_list.append(pvalue)\n",
    "    print(f' ANOVA Result for {i} vs. High_Unemployment\\n {st.f_oneway(group1,group2)}\\n==================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "significant_list=[1 if i <=0.05 else 0 for i in pvalue_list]\n",
    "anova=pd.DataFrame({'Feature':feature_list,'Statistic':statistic_list,'Pvalue':pvalue_list,'Significant':significant_list})\n",
    "anova.sort_values('Pvalue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#scatter plots for weigthed feature scroes by unemployment rate\n",
    "row=0\n",
    "col=0\n",
    "fig,axes=plt.subplots(3,3,figsize=(15,15))\n",
    "\n",
    "for i in feature_list:\n",
    "    if col>2:\n",
    "        row+=1\n",
    "        col=0\n",
    "        sns.scatterplot(x='Unemployment Rate',y=i,hue='High_Unemployment',data=music_unemployment_group_y,ax=axes[row][col])\n",
    "        col+=1\n",
    "        \n",
    "    else:\n",
    "        sns.scatterplot(x='Unemployment Rate',y=i,hue='High_Unemployment',data=music_unemployment_group_y,ax=axes[row][col])\n",
    "        col+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=0\n",
    "fig,axes=plt.subplots(2,1,figsize=(10,10))\n",
    "for i in anova['Feature'][anova['Significant']==1]:\n",
    "    sns.boxplot(x='High_Unemployment',y=i,data=music_unemployment_group_y[[i,'High_Unemployment']],ax=axes[n])\n",
    "    n+=1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# End of Will's Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Happiness in a song did not have a strong correlation with the U.S. Employment Rate. However, we did discover that energy does have a correlation. When there is a high unemployment rate in the U.S., the top billboard songs are more likely to have higher energy than when there is a low unemployment rate.\n",
    "\n",
    "This is not great news for Taylor Swift's new album \"folklore\" that came out last week."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
