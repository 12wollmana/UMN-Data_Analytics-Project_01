{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis\n",
    "\n",
    "<em>Aaron Wollman, Albin Joseph, Kelsey Richardson Blackwell, Will Huang</em>\n",
    "\n",
    "In this notebook, the code will look at data from Spotify, Billboard, and the US Bureau of Labor Statistics to try to answer the following questions:\n",
    "<ul>\n",
    "    <li>Is there a correlation between unemployment and the Billboard Top 100 Songs Chart?  If so, can the data predict what the next top song might sound like?\n",
    "    </li>\n",
    "    <li>\n",
    "        Are there other musical attributes besides happiness that have a stronger correlation such as danceability, energy, tempo, speech?\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statistics\n",
    "import numpy as np\n",
    "from scipy.stats import linregress\n",
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get constants\n",
    "from columns import Music_Unemploy_Cols, Unemploy_Cols\n",
    "from datafiles import music_unemployment, unemployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Music and Unemployment CSV\n",
    "music_unemployment = pd.read_csv(music_unemployment, index_col = 0)\n",
    "music_unemployment.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unemployment Rate\n",
    "\n",
    "Before we jumped into running recressions and statistical tests, we wanted to understand the in the unemployment rate during the timeframe. We wanted to visually understand the changes, so we created a heat map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Unemployment Data file\n",
    "unemployment_time = pd.read_csv(unemployment, index_col = 0)\n",
    "unemployment_time = unemployment_time.dropna()\n",
    "unemployment_time = unemployment_time.loc[unemployment_time[Unemploy_Cols.year] < 2020]\n",
    "unemployment_time.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment_rate_list=unemployment_time[Unemploy_Cols.rate]\n",
    "plt.boxplot(unemployment_rate_list)\n",
    "plt.title(\"Box Plot of Unemployment Rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot the table to give a yearly view.\n",
    "unemployment_time_pivot=unemployment_time.pivot(\n",
    "    Unemploy_Cols.year, Unemploy_Cols.month, Unemploy_Cols.rate)\n",
    "unemployment_time_pivot.dropna()\n",
    "unemployment_time_pivot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To show the how the unemployment rate has changed over time, the code will use a heatmap. The darker the shade of blue, the higher the unemployment rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show Unemployment Rate heatmap per decade.\n",
    "vmax_un = unemployment_time_pivot.max().max()\n",
    "vmin_un = unemployment_time_pivot.min().min()\n",
    "\n",
    "fig,axes = plt.subplots(6,1,figsize=(10,20),sharex=True)\n",
    "i = 0\n",
    "for axis in axes:\n",
    "    data = unemployment_time_pivot[i*10 : (i+1) * 10]\n",
    "    axis.set_title(f\"Unemployment in the {1960 + (i*10)}s\")\n",
    "    sns.heatmap(data,cmap = (\"Blues\"),ax = axis,vmax = vmax_un, vmin = vmin_un)\n",
    "    i += 1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the heatmap there are a few observable trends:\n",
    "* Higher unemployment rates usually lasted for several years\n",
    "* Unemployment rate usually went high (above 7) once a decade\n",
    "* The highest unemployment timeframes occurred in 1982-1083 and 2009-2011"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Song Valence\n",
    "[Spotify's API](https://developer.spotify.com/documentation/web-api/reference/tracks/get-audio-features/) defines a song's valence as:\n",
    "<blockquote>\"A measure from 0.0 to 1.0 describing the musical positiveness conveyed by a track. Tracks with high valence sound more positive (e.g. happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry).\"</blockquote>\n",
    "\n",
    "For this project, this can be considered our \\\"happiness\\\" metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code will run a similar heat map for the valence score, to help us visually understand the changes in such a large timeframe.\n",
    "\n",
    "Now it is time to do the work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Weighted Valence\n",
    "music_unemployment[\"weighed valence\"] = music_unemployment[\"valence\"] * (101 - music_unemployment[\"Placement\"])\n",
    "valence_year_month=music_unemployment.groupby(['Year','Month'])['weighed valence'].mean()\n",
    "valence_year_month_df=pd.DataFrame(valence_year_month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_list=list(range(1,13))\n",
    "year_list=list(music_unemployment['Year'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valence_df=pd.DataFrame(columns = month_list,index=year_list)\n",
    "for i in year_list:\n",
    "    valence_df.loc[i]=valence_year_month[(i)]\n",
    "\n",
    "valence_df.columns.name = 'Month'\n",
    "valence_df.index.name = 'Year'\n",
    "valence_df=valence_df.astype(float)\n",
    "valence_df.sort_index(inplace=True)\n",
    "valence_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valence heat map by decades\n",
    "vmax=valence_df.max().max()\n",
    "vmin=valence_df.min().min()\n",
    "\n",
    "fig,axes=plt.subplots(6,1,figsize=(15,20))\n",
    "\n",
    "for n,j in zip(range(0,6),range(0,60,10)):\n",
    "    sns.heatmap(valence_df[j:j+10],cmap=(\"Blues\"),ax=axes[n],vmax=vmax,vmin=vmin)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the heatmap, it looks like people tend to listen to sad song more in the past 3 decades."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Song Valence vs Unemployment\n",
    "In the next cell, the code will display the heatmaps for the song valence and unemployment side-by-side for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display unemployment and valence heatmaps side-by-side.\n",
    "fig,axes=plt.subplots(6,2,figsize=(15,20))\n",
    "for n,j in zip(range(0,6),range(0,60,10)):\n",
    "    sns.heatmap(unemployment_time_pivot[j:j+10],cmap=(\"Blues\"),ax=axes[n][0],vmax=vmax_un,vmin=vmin_un)\n",
    "for n,j in zip(range(0,6),range(0,60,10)):\n",
    "    sns.heatmap(valence_df[j:j+10],cmap=(\"Blues\"),ax=axes[n][1],vmax=vmax,vmin=vmin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the heatmaps, there doesn't appear to have much correlation.  However, it would still be good to see mathematically if this is the case. Let's do a regression on them to see how the points line up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for plotting a regression\n",
    "def regression_plot(dataframe, x_col, y_col):\n",
    "    # Plot the scatter plot\n",
    "    dataframe.plot(kind=\"scatter\", x = x_col, y = y_col)\n",
    "    \n",
    "    # Calculate the correlation coefficient and linear regression model \n",
    "    x_values = dataframe[x_col]\n",
    "    y_values = dataframe[y_col]\n",
    "    (slope, intercept, rvalue, pvalue, stderr) = linregress(x_values, y_values)\n",
    "    regress_values = x_values * slope + intercept\n",
    "    equation = \"y = \" + str(round(slope,2)) + \"x + \" + str(round(intercept,2))\n",
    "    eq_label = f\"{equation} \\nr-squared = {round(rvalue * rvalue, 3)}\"\n",
    "    regress_plot, = plt.plot(x_values, regress_values, \"r-\", label=eq_label)\n",
    "    plt.legend(handles=[regress_plot], loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by the song's date\n",
    "date_cols = [Music_Unemploy_Cols.year, \n",
    "             Music_Unemploy_Cols.month, \n",
    "             Music_Unemploy_Cols.day]\n",
    "music_unemployment_gb = music_unemployment.groupby(date_cols)\n",
    "\n",
    "# Find the average of unemployment rate and weighed valence for each date\n",
    "avg_music_unemploy = music_unemployment_gb.mean()\n",
    "rate_v_valence = avg_music_unemploy[[Music_Unemploy_Cols.unemploy_rate, \n",
    "                                     Music_Unemploy_Cols.valence]]\n",
    "\n",
    "# Create a Scatter Graph\n",
    "regression_plot(rate_v_valence, \n",
    "                Music_Unemploy_Cols.unemploy_rate, \n",
    "                Music_Unemploy_Cols.valence)\n",
    "plt.title(\"Unemployment Rate vs. Valence (Happiness)\")\n",
    "plt.xlabel(\"Unemployment Rate\")\n",
    "plt.ylabel(\"Valence (Happiness)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above graph, there is <b>not</b> a good correlation between valence and the unemployment rate. With the above, the data doesn't take the song's placement in the Top 100 into account. Let's try again using a weighted average of the Top 100.\n",
    "\n",
    "This weighted average will give the number 1 song 101 points, number 2 100 points, and will keep decreasing by 1 point until it assigns the number 100 song 1 point. By doing this weighted average, the placement of a song on the Top 100 will be more meaningful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new data point \"Weighted Valence\"\n",
    "Music_Unemploy_Cols.weighed_valence = \"weighed valence\"\n",
    "weights = (101 - music_unemployment[Music_Unemploy_Cols.placement])\n",
    "weighed_valence = music_unemployment[Music_Unemploy_Cols.valence] * weights\n",
    "music_unemployment[Music_Unemploy_Cols.weighed_valence] = weighed_valence\n",
    "music_unemployment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by the song's date\n",
    "music_unemployment_gb = music_unemployment.groupby(date_cols)\n",
    "\n",
    "# Find the average of unemployment rate and weighed valence for each date\n",
    "avg_music_unemploy = music_unemployment_gb.mean()\n",
    "rate_v_valence = avg_music_unemploy[[Music_Unemploy_Cols.unemploy_rate, \n",
    "                                     Music_Unemploy_Cols.weighed_valence]]\n",
    "\n",
    "# Create a Scatter Graph\n",
    "regression_plot(rate_v_valence, \n",
    "                Music_Unemploy_Cols.unemploy_rate, \n",
    "                Music_Unemploy_Cols.weighed_valence)\n",
    "plt.title(\"Unemployment Rate vs. Valence (Happiness)\")\n",
    "plt.xlabel(\"Unemployment Rate\")\n",
    "plt.ylabel(\"Weighed Valence (Happiness)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even with a weighted average, there still isn't a good correlation between the average valence and the unemployment rate for all decades."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unemployment Rate vs. Valence in Songs 2010-2019\n",
    "\n",
    "Even if the code didn't provide a good correlation between unemployment and song valence from 1960 and now, musical tastes do change. This code will look at the correlation between 2010 and 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the data for songs 2010 and after\n",
    "music_unemployment_years = (music_unemployment.loc[(music_unemployment[\"Year\"]) >= 2010])\n",
    "\n",
    "# Group by the song's date\n",
    "music_unemployment_years_gb = music_unemployment_years.groupby([\"Year\", \"Month\", \"Day\"])\n",
    "\n",
    "# Find the average of unemployment rate and weighed valence for each date\n",
    "two_rate_v_valence = music_unemployment_years_gb.mean()[[\"Unemployment Rate\", \"weighed valence\"]]\n",
    "\n",
    "# Create a Scatter Graph\n",
    "regression_plot(two_rate_v_valence, \"Unemployment Rate\", \"weighed valence\")\n",
    "plt.title(\"Unemployment Rate vs. Valence in Songs 2010-2019\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the graph above, it is observable that looking at songs between 2010 and 2019 provides a better correlation than looking at all decades.  It's still not great though, with a r-squared value less than 0.5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valence vs. Unemployment Conclusion: \n",
    "\n",
    "We discovered the unemployment rate does not impact happiness in a Top 100 hit song. As you can see in the regression graphs above, the r-squared value shows there was not a strong correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding an Alternative Music Attribute\n",
    "Although there wasn't a great correlation between song valence and unemployment, that doesn't mean that there might not be a correlation between unemployment and another data attribute. This code will conduct an ANOVA test to see what other attributes might be worth looking into for a regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's categorize songs into high and low unemployment.  From the boxplot in the Unemployment section, an unemployment rate above 7 is in the 3rd quartile, which can be considered high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorize song by its unemployment rate at the time\n",
    "# if unemployment rate higher than 7.0, assign into High_Unemployment group\n",
    "# 7.0 is descided by the 3rd quantile of all the unemployment rate data\n",
    "\n",
    "high_unemployment_rate=np.quantile(unemployment_rate_list, .75) ###7.0\n",
    "music_unemployment[\"weighed valence\"] = music_unemployment[\"valence\"] * (101 - music_unemployment[\"Placement\"])\n",
    "music_unemployment['High_Unemployment'] = music_unemployment['Unemployment Rate'].apply(lambda x: 1 if x>=high_unemployment_rate else 0)\n",
    "\n",
    "music_unemployment.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's weigh the attributes according to their position on the Top 100 Charts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the calculation of weighted features could be done together \n",
    "music_weights = (101 - music_unemployment[\"Placement\"])\n",
    "music_unemployment[\"weighed valence\"] = music_unemployment[\"valence\"] * music_weights\n",
    "music_unemployment['weighed danceability']=music_unemployment[\"danceability\"] * music_weights\n",
    "music_unemployment['weighed energy']=music_unemployment[\"energy\"] * music_weights\n",
    "music_unemployment['weighed key']=music_unemployment[\"key\"] * music_weights\n",
    "music_unemployment['weighed loudness']=music_unemployment[\"loudness\"] * music_weights\n",
    "music_unemployment['weighed speechiness']=music_unemployment[\"speechiness\"] * music_weights\n",
    "music_unemployment['weighed acousticness']=music_unemployment[\"acousticness\"] * music_weights\n",
    "music_unemployment['weighed liveness']=music_unemployment[\"liveness\"] * music_weights\n",
    "music_unemployment['weighed tempo']=music_unemployment[\"tempo\"] * music_weights\n",
    "music_unemployment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign the weighted feature scores to the mean of the monthly feature score\n",
    "music_unemployment_group=music_unemployment.groupby(['Year','Month','Day'])[\n",
    "    ['High_Unemployment','Unemployment Rate',\n",
    "       'weighed valence', 'weighed danceability', 'weighed energy',\n",
    "       'weighed key', 'weighed loudness', 'weighed speechiness',\n",
    "       'weighed acousticness', 'weighed liveness', 'weighed tempo']].mean()\n",
    "music_unemployment_group.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list=['weighed valence', 'weighed danceability', 'weighed energy',\n",
    "       'weighed key', 'weighed loudness', 'weighed speechiness',\n",
    "       'weighed acousticness', 'weighed liveness', 'weighed tempo']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below graphs show the distribution of attributes for high and low unemployment rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# scatter plots for weigthed feature scroes by unemployment rate\n",
    "row=0\n",
    "col=0\n",
    "fig,axes=plt.subplots(3,3,figsize=(15,15))\n",
    "\n",
    "for i in feature_list:\n",
    "    if col>2:\n",
    "        row+=1\n",
    "        col=0\n",
    "        sns.scatterplot(x='Unemployment Rate',y=i,hue='High_Unemployment',data=music_unemployment_group,ax=axes[row][col])\n",
    "        col+=1\n",
    "        \n",
    "    else:\n",
    "        sns.scatterplot(x='Unemployment Rate',y=i,hue='High_Unemployment',data=music_unemployment_group,ax=axes[row][col])\n",
    "        col+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, the code will conduct the ANOVA tests on the weighted features vs unemployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conduct Anova test for weighted features\n",
    "statistic_list=[]\n",
    "pvalue_list=[]\n",
    "for i in feature_list:\n",
    "    group1=music_unemployment_group[i][music_unemployment_group['High_Unemployment']==1]\n",
    "    group2=music_unemployment_group[i][music_unemployment_group['High_Unemployment']==0]\n",
    "    statistic=st.f_oneway(group1,group2)[0]\n",
    "    pvalue=st.f_oneway(group1,group2)[1]\n",
    "    statistic_list.append(statistic)\n",
    "    pvalue_list.append(pvalue)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anova test results dataframe\n",
    "significant_list=[1 if i <=0.05 else 0 for i in pvalue_list]\n",
    "anova=pd.DataFrame({'Feature':feature_list,'Statistic':statistic_list,'Pvalue':pvalue_list,'Significant':significant_list})\n",
    "anova.sort_values('Pvalue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above table of ANOVA test results, energy and tempo give the smallest P-Values.  This means that they have a higher chance of correlation with unemployment than other attributes. Below is the box-plots of each of the attributes tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Boxplots for the weighted fetures which has significant \n",
    "row=0\n",
    "col=0\n",
    "fig,axes=plt.subplots(2,3,figsize=(15,10))\n",
    "for i in anova['Feature'][anova['Significant']==1]:\n",
    "    if col>2:\n",
    "        row+=1\n",
    "        col=0\n",
    "        sns.boxplot(x='High_Unemployment',y=i,data=music_unemployment_group[[i,'High_Unemployment']],ax=axes[row][col])\n",
    "        col+=1\n",
    "        \n",
    "    else:\n",
    "        sns.boxplot(x='High_Unemployment',y=i,data=music_unemployment_group[[i,'High_Unemployment']],ax=axes[row][col])\n",
    "        col+=1\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unemployment Rate vs. Tempo\n",
    "\n",
    "From the ANOVA test, we knew that energy and tempo may correlate with the unemployment rate.\n",
    "\n",
    "We ran a regression for the unemployment rate versus tempo for the whole timeframe and since 2010. In both graphs, the r-squared values were not significant enough to show us a correlation between unemployment rate vs. tempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new data point \"Weighed Tempo\"\n",
    "music_unemployment[\"weighed energy\"] = music_unemployment[\"energy\"] * (101 - music_unemployment[\"Placement\"])\n",
    "\n",
    "#Create a weighed tempo\n",
    "music_unemployment[\"weighed tempo\"] = music_unemployment[\"tempo\"] * (101 - music_unemployment[\"tempo\"])\n",
    "\n",
    "# Group by the song's date\n",
    "music_unemployment_gb = music_unemployment.groupby([\"Year\", \"Month\", \"Day\"])\n",
    "\n",
    "# Find the average of unemployment rate and weighed valence for each date\n",
    "rate_v_tempo = music_unemployment_gb.mean()[[\"Unemployment Rate\", \"weighed tempo\"]]\n",
    "\n",
    "# Create a Scatter Graph\n",
    "regression_plot(rate_v_tempo, \"Unemployment Rate\", \"weighed tempo\")\n",
    "plt.title(\"Unemployment Rate vs. Tempo\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the tempo vs unemployment for all decades didn't give a good correlation either, with the r-squared being far below 0.5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unemployment Rate vs. Tempo in Songs 2010-2019\n",
    "While all decades didn't give a good result, maybe songs between 2010 and 2019 will give a better result?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Find the data for songs 2010 and after\n",
    "music_unemployment_years = (music_unemployment.loc[(music_unemployment[\"Year\"]) >= 2010])\n",
    "\n",
    "# Group by the song's date\n",
    "music_unemployment_years_gb = music_unemployment_years.groupby([\"Year\", \"Month\", \"Day\"])\n",
    "\n",
    "# Find the average of unemployment rate and weighed valence for each date\n",
    "two_rate_v_tempo = music_unemployment_years_gb.mean()[[\"Unemployment Rate\", \"weighed tempo\"]]\n",
    "\n",
    "# Create a Scatter Graph\n",
    "regression_plot(two_rate_v_tempo, \"Unemployment Rate\", \"weighed tempo\")\n",
    "plt.title(\"Unemployment Rate vs. Tempo in Song 2010-2019\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the above graph, narrowing the years didn't help much either.  The r-squared value is still below 0.5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unemployment Rate vs. Energy\n",
    "\n",
    "We ran a regression for the unemployment rate versus tempo for the whole timeframe and since 2010."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a weighed energy\n",
    "music_unemployment[\"weighed energy\"] = music_unemployment[\"energy\"] * (101 - music_unemployment[\"Placement\"])\n",
    "\n",
    "# Group by the song's date\n",
    "music_unemployment_gb = music_unemployment.groupby([\"Year\", \"Month\", \"Day\"])\n",
    "\n",
    "# Find the average of unemployment rate and weighed valence for each date\n",
    "rate_v_energy = music_unemployment_gb.mean()[[\"Unemployment Rate\", \"weighed energy\"]]\n",
    "\n",
    "# Create a Scatter Graph\n",
    "regression_plot(rate_v_energy, \"Unemployment Rate\", \"weighed energy\")\n",
    "plt.title(\"Unemployment Rate vs. Energy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Across all decades, energy and unemployment don't have much of a correlation either.  The r-squared value is below 0.5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unemployment Rate vs. Energy in Songs 2010-2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with the other attributes observed, maybe looking at data between 2010 and 2019 will give a better result?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the data for songs 2010 and after\n",
    "music_unemployment_years = (music_unemployment.loc[(music_unemployment[\"Year\"]) >= 2010])\n",
    "                                  \n",
    "# Group by the song's date\n",
    "music_unemployment_years_gb = music_unemployment_years.groupby([\"Year\", \"Month\", \"Day\"])\n",
    "\n",
    "# Find the average of unemployment rate and weighed valence for each date\n",
    "two_rate_v_energy = music_unemployment_years_gb.mean()[[\"Unemployment Rate\", \"weighed energy\"]]\n",
    "\n",
    "# Create a Scatter Graph\n",
    "regression_plot(two_rate_v_energy, \"Unemployment Rate\", \"weighed energy\")\n",
    "plt.title(\"Unemployment Rate vs. Energy in Songs 2010-2019\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph for energy vs unemployment between 2010 and 2019 finally gives a great correlation.  The r-squared value is well above 0.5 and is above 0.85.  This means that predictions might be possible off of this model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Happiness in a song did not have a strong correlation with the U.S. Employment Rate. However, we did discover that energy does have a correlation if the data is limited to 2010 through 2019.\n",
    "\n",
    "When there is a high unemployment rate in the U.S., the top billboard songs are more likely to have higher energy than when there is a low unemployment rate.\n",
    "\n",
    "This is not great news for Taylor Swift's new album \"folklore\" that came out last week, which is more mellow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
